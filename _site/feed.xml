<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.6.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2018-07-06T11:54:30+08:00</updated><id>http://localhost:4000/</id><title type="html">David Sasson</title><subtitle>A blog about technology and health related stuff</subtitle><entry><title type="html">How to Cross Register</title><link href="http://localhost:4000/evals/" rel="alternate" type="text/html" title="How to Cross Register" /><published>2018-05-15T00:00:00+08:00</published><updated>2018-05-15T00:00:00+08:00</updated><id>http://localhost:4000/evals</id><content type="html" xml:base="http://localhost:4000/evals/">&lt;p&gt;Deciding what to learning can seem daunting at times. With tons of interesting courses and life-changing professors, how does one choose which classes to take? I decided to investigate this quesiton using my school’s &lt;a href=&quot;https://www.hsph.harvard.edu/office-of-education/course-evaluations/&quot;&gt;course evaluations&lt;/a&gt;, &lt;a href=&quot;http://ggplot2.tidyverse.org/&quot;&gt;ggplot2&lt;/a&gt;, and &lt;a href=&quot;https://www.tidytextmining.com/&quot;&gt;tidytext&lt;/a&gt;. Code is available &lt;a href=&quot;https://www.github.com/dsasson48/evals&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;results&quot;&gt;Results&lt;/h3&gt;

&lt;p&gt;Each course evaluation has three quesitons regarding teaching quality with scores from 1-5 corresponding to agreeability. There is also a free text section for comments.&lt;/p&gt;

&lt;p&gt;First, the three questions are all highly correlated. Not too suprising that highly rated courses have good teachers.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/corr.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Looks like 2016 had more respondents than the previous year.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/yr.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And schools have different popularity over years.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/schools.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As well as each school’s overall rating&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/rating.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To make sense of the comments, each word is assigned a score from -5 to +5 corresponding to the overall sentiment expressed, as seen in this cloud.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/words.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Here is the word frequency in certain classes
&lt;img src=&quot;/assets/images/freq.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We can average the sentiment from school specific comments and compare
&lt;img src=&quot;/assets/images/sent_school.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Finally, this plot shows the distribtution of word scores for each school
&lt;img src=&quot;/assets/images/dist.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;psa&quot;&gt;PSA&lt;/h1&gt;

&lt;p&gt;In case you’re wondering: yes, I am that much of a nerd.&lt;/p&gt;</content><author><name></name></author><category term="blog" /><category term="learning" /><category term="data viz" /><category term="sentiment analysis" /><summary type="html">Deciding what to learning can seem daunting at times. With tons of interesting courses and life-changing professors, how does one choose which classes to take? I decided to investigate this quesiton using my school’s course evaluations, ggplot2, and tidytext. Code is available here.</summary></entry><entry><title type="html">Three thoughts on Dr. Google</title><link href="http://localhost:4000/goog/" rel="alternate" type="text/html" title="Three thoughts on Dr. Google" /><published>2018-03-26T00:00:00+08:00</published><updated>2018-03-26T00:00:00+08:00</updated><id>http://localhost:4000/goog</id><content type="html" xml:base="http://localhost:4000/goog/">&lt;p&gt;Earlier this month Verily came out with an interesting &lt;a href=&quot;https://goo.gl/fTtQCu&quot;&gt;piece of software&lt;/a&gt; that identifies several covariates with surprising accuracy from retinal scans of 300,000 patients. These features are fed into a model which yields the probability of suffering a major cardiac event. Although we’ve seen several versions of medical algorithms that aim to supplement or (gasp) replace physicians, this tech is unique in that it’s trying to repurpose existing data. Furthermore, the combination of a massive shortage of clinicians and the leading cause of death worldwide means a huge potential for disruption.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/goog.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Although they made the headlines, the ugly underbelly of this technology is dependent on agile and interoperable hospital systems–both of which have made tremendous progress over the past decade (&lt;a href=&quot;https://obamawhitehouse.archives.gov/blog/2013/05/24/more-half-doctors-now-use-electronic-health-records-thanks-administration-policies&quot;&gt;Thanks, Obama&lt;/a&gt;). Google has deep learning experts and world renowned scientists, but at the end of the day any team’s ability is a function of data quality and quantity. Open source, clean, and anonymized medical records are critical. We have a long way to go until CSV heaven.&lt;/p&gt;

&lt;p&gt;Finally, with new machine learning applications coming right and left when are we actually going to start trusting these things? Obviously, this method needs to be thoroughly validated before it can be used in a clinical setting, but when is “good” good enough? The traditional &lt;a href=&quot;https://en.wikipedia.org/wiki/HeartScore&quot;&gt;Systematic COronary Risk Evaluation&lt;/a&gt; or “SCORE” method of predicting risk is correct 72% of the time, while Google’s was correct 70% of the time. How much strategic risk are health care organizations willing to take on for innovative technologies or increased productivity?&lt;/p&gt;

&lt;p&gt;I sure as hell don’t have the answers, but the first step is asking the right questions.&lt;/p&gt;</content><author><name></name></author><category term="blog" /><category term="machine learning" /><category term="healthcare" /><category term="hype" /><summary type="html">Earlier this month Verily came out with an interesting piece of software that identifies several covariates with surprising accuracy from retinal scans of 300,000 patients. These features are fed into a model which yields the probability of suffering a major cardiac event. Although we’ve seen several versions of medical algorithms that aim to supplement or (gasp) replace physicians, this tech is unique in that it’s trying to repurpose existing data. Furthermore, the combination of a massive shortage of clinicians and the leading cause of death worldwide means a huge potential for disruption.</summary></entry></feed>